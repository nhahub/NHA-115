{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ZFeWtrzo6TcOIToGjHrjO3Mgqn2MK7z1",
      "authorship_tag": "ABX9TyMsp7qNb/79USkKtOloXT9D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhahub/NHA-115/blob/main/IotLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only if pyodbc driver is missing in Colab. May require runtime restart.\n",
        "!apt-get update -qq\n",
        "!apt-get install -y curl gnupg2 apt-transport-https\n",
        "!curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "!curl https://packages.microsoft.com/config/ubuntu/22.04/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "!apt-get update -qq\n",
        "!ACCEPT_EULA=Y apt-get install -y msodbcsql18 unixodbc-dev\n"
      ],
      "metadata": {
        "id": "qo2U9udJpb0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run once in Colab\n",
        "!pip install transformers accelerate torch bitsandbytes sentencepiece pyodbc pandas --quiet\n",
        "print(\"Packages install step finished.\")\n"
      ],
      "metadata": {
        "id": "IME3zvPcpp0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Imports and configuration\n",
        "import re, json, time\n",
        "import pyodbc\n",
        "import pandas as pd\n",
        "from datetime import datetime, timezone\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import statistics\n",
        "\n",
        "# ====== EDIT THESE ======\n",
        "SERVER   = \"iotsynaps.sql.azuresynapse.net\"\n",
        "DATABASE = \"iotsqlpool\"\n",
        "USERNAME = \"sqladminuser\"\n",
        "PASSWORD = \"Babytools123\"\n",
        "\n",
        "IOT_TABLE    = \"dbo.IoT_AirQuality\"\n",
        "REPORT_TABLE = \"dbo.AI_Reports\"\n",
        "\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "MODEL_DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "MAX_NEW_TOKENS = 300\n",
        "TEMPERATURE = 0.4\n",
        "RETRY_TEMPERATURE = 0.18\n",
        "\n",
        "THRESH = {\"pm25\": 15.0, \"pm10\": 45.0, \"no2\": 25.0, \"co2\": 450.0}\n",
        "GENERATED_BY = \"Mistral-7B Q4\"\n",
        "\n",
        "print(\"Config set. Device:\", MODEL_DEVICE)\n"
      ],
      "metadata": {
        "id": "t6UptE2m0qfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Helper functions\n",
        "\n",
        "def extract_number_from_text(s):\n",
        "    if s is None: return None\n",
        "    if not isinstance(s, str):\n",
        "        try: return float(s)\n",
        "        except: return None\n",
        "    s_clean = s.replace(\"µ\", \"u\").replace(\"μ\", \"u\")\n",
        "    m = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s_clean)\n",
        "    return float(m.group()) if m else None\n",
        "\n",
        "def compute_stats_from_series(series):\n",
        "    nums = [extract_number_from_text(x) for x in series.dropna().astype(str)]\n",
        "    nums = [n for n in nums if n is not None]\n",
        "    if not nums: return (None, None, None)\n",
        "    return (round(statistics.mean(nums),2), round(max(nums),2), round(min(nums),2))\n",
        "\n",
        "def compute_status(avg_pm25, avg_pm10, max_co2, max_no2):\n",
        "    status = \"Green\"\n",
        "    for key, val in [(\"pm25\", avg_pm25), (\"pm10\", avg_pm10), (\"co2\", max_co2), (\"no2\", max_no2)]:\n",
        "        if val is None: continue\n",
        "        thr = THRESH.get(key)\n",
        "        if thr is None: continue\n",
        "        if val > 2 * thr: return \"Red\"\n",
        "        if val > thr: status = \"Yellow\"\n",
        "    return status\n",
        "\n",
        "def detect_high_risk_regions(df):\n",
        "    if not {'region','pm25','pm10'}.issubset(df.columns): return []\n",
        "    df2 = df.copy()\n",
        "    df2['_pm25_val'] = df2['pm25'].apply(extract_number_from_text)\n",
        "    df2['_pm10_val'] = df2['pm10'].apply(extract_number_from_text)\n",
        "    mask = (df2['_pm25_val'] > 50) | (df2['_pm10_val'] > 100)\n",
        "    return df2.loc[mask, 'region'].dropna().unique().tolist()\n",
        "\n",
        "def load_iot_data(hours_back=1, top_n=1000):\n",
        "    conn_str = (\n",
        "        f\"Driver={{ODBC Driver 18 for SQL Server}};\"\n",
        "        f\"Server={SERVER};Database={DATABASE};Uid={USERNAME};Pwd={PASSWORD};\"\n",
        "        f\"Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
        "    )\n",
        "    conn = pyodbc.connect(conn_str)\n",
        "    query = f\"\"\"\n",
        "    SELECT TOP ({top_n}) region, [timestamp], temperature, humidity, co2, no2, pm25, pm10\n",
        "    FROM {IOT_TABLE}\n",
        "    WHERE [timestamp] >= DATEADD(hour, -{int(hours_back)}, SYSUTCDATETIME())\n",
        "    ORDER BY [timestamp] DESC\n",
        "    \"\"\"\n",
        "    df = pd.read_sql(query, conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "def compute_metrics_and_prepare(df, hours_back):\n",
        "    avg_pm25, max_pm25, min_pm25 = compute_stats_from_series(df['pm25']) if 'pm25' in df.columns else (None,None,None)\n",
        "    avg_pm10, max_pm10, min_pm10 = compute_stats_from_series(df['pm10']) if 'pm10' in df.columns else (None,None,None)\n",
        "    avg_co2, max_co2, min_co2   = compute_stats_from_series(df['co2']) if 'co2' in df.columns else (None,None,None)\n",
        "    avg_no2, max_no2, min_no2   = compute_stats_from_series(df['no2']) if 'no2' in df.columns else (None,None,None)\n",
        "\n",
        "    statistics_dict = {\n",
        "        \"avg_pm25\": avg_pm25, \"avg_pm10\": avg_pm10, \"max_co2\": max_co2, \"max_no2\": max_no2,\n",
        "        \"min_pm25\": min_pm25, \"min_pm10\": min_pm10, \"min_co2\": min_co2, \"min_no2\": min_no2,\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"time_range\": f\"last {hours_back} hours\",\n",
        "        \"statistics\": statistics_dict,\n",
        "        \"samples\": {col: df[col].dropna().astype(str).tolist()[:100] for col in ['pm25','pm10','co2','no2'] if col in df.columns},\n",
        "        \"high_risk_regions\": detect_high_risk_regions(df),\n",
        "        \"status\": compute_status(avg_pm25, avg_pm10, max_co2, max_no2)\n",
        "    }\n",
        "    return payload\n"
      ],
      "metadata": {
        "id": "iBZdC-0e0sZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Load tokenizer & model\n",
        "print(\"Loading tokenizer and model (4-bit)...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    load_in_4bit=True,\n",
        "    offload_folder=\"/tmp/offload\"\n",
        ")\n",
        "print(\"Model loaded on device:\", MODEL_DEVICE)\n"
      ],
      "metadata": {
        "id": "PwUfkjGr0t8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Build prompt & generate report\n",
        "def build_prompt(payload):\n",
        "    s = payload['statistics']\n",
        "    samples = payload['samples']\n",
        "    high_regions = payload['high_risk_regions']\n",
        "    time_range = payload['time_range']\n",
        "\n",
        "    return f\"\"\"\n",
        "You are an expert environmental scientist. Produce a concise professional English summary and a final status (Green/Yellow/Red).\n",
        "Use numeric stats for calculations and samples (which include units) as supporting evidence.\n",
        "\n",
        "Time range: {time_range}\n",
        "\n",
        "Instructions:\n",
        "1) Output a short professional summary (4-6 sentences) with:\n",
        "   - Overall status\n",
        "   - Pollutants exceeding WHO limits\n",
        "   - 2 actionable recommendations\n",
        "2) Output EXACTLY one JSON block with keys:\n",
        "   avg_pm25, avg_pm10, max_co2, max_no2, high_risk_regions, status\n",
        "\n",
        "Numeric stats:\n",
        "avg_pm25 = {s['avg_pm25']}\n",
        "avg_pm10 = {s['avg_pm10']}\n",
        "max_co2  = {s['max_co2']}\n",
        "max_no2  = {s['max_no2']}\n",
        "\n",
        "Sample PM2.5: {samples.get('pm25', [])[:10]}\n",
        "Sample PM10: {samples.get('pm10', [])[:10]}\n",
        "\n",
        "High risk regions: {high_regions}\n",
        "\n",
        "Now generate the report.\n",
        "\"\"\"\n",
        "\n",
        "def generate_report(prompt_text, temp=TEMPERATURE):\n",
        "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(MODEL_DEVICE)\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=MAX_NEW_TOKENS,\n",
        "        do_sample=True,\n",
        "        temperature=temp\n",
        "    )\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "def produce_summary_and_json(payload):\n",
        "    prompt_text = build_prompt(payload)\n",
        "    report_raw = generate_report(prompt_text, temp=TEMPERATURE)\n",
        "\n",
        "    # Retry if summary too short\n",
        "    if len(report_raw.split(\"{\")[0].strip()) < 20 or \"You are an expert\" in report_raw:\n",
        "        report_raw = generate_report(prompt_text, temp=RETRY_TEMPERATURE)\n",
        "\n",
        "    matches = re.findall(r\"\\{.*?\\}\", report_raw, re.DOTALL)\n",
        "    parsed_json = None\n",
        "    if matches:\n",
        "        json_text = matches[-1].replace(\"'\", '\"')\n",
        "        json_text = re.sub(r\",\\s*}\", \"}\", json_text)\n",
        "        json_text = re.sub(r\",\\s*]\", \"]\", json_text)\n",
        "        try: parsed_json = json.loads(json_text)\n",
        "        except: parsed_json = None\n",
        "\n",
        "    # Clean text summary\n",
        "    if parsed_json:\n",
        "        text_summary = report_raw.split(matches[-1])[0].strip()\n",
        "    else:\n",
        "        s = payload['statistics']\n",
        "        text_summary = (\n",
        "            f\"Air quality status: {payload['status']}. \"\n",
        "            f\"Avg PM2.5: {s.get('avg_pm25')}, PM10: {s.get('avg_pm10')}, \"\n",
        "            f\"Max CO2: {s.get('max_co2')}, Max NO2: {s.get('max_no2')}. \"\n",
        "            f\"High risk regions: {', '.join(payload['high_risk_regions']) or 'None'}.\"\n",
        "        )\n",
        "        parsed_json = {\n",
        "            \"avg_pm25\": s.get('avg_pm25'),\n",
        "            \"avg_pm10\": s.get('avg_pm10'),\n",
        "            \"max_co2\": s.get('max_co2'),\n",
        "            \"max_no2\": s.get('max_no2'),\n",
        "            \"high_risk_regions\": payload['high_risk_regions'],\n",
        "            \"status\": payload['status']\n",
        "        }\n",
        "\n",
        "    text_summary = re.sub(r\"(?i)you are an expert.*?Now generate the report\\.\", \"\", text_summary, flags=re.DOTALL).strip()\n",
        "    return text_summary, parsed_json, report_raw\n"
      ],
      "metadata": {
        "id": "c7OslXoc0v8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Insert report into SQL\n",
        "def insert_report_into_sql(ai_text_summary, stats_dict, high_regions, hours_back):\n",
        "    conn_str = (\n",
        "        f\"Driver={{ODBC Driver 18 for SQL Server}};\"\n",
        "        f\"Server={SERVER};Database={DATABASE};Uid={USERNAME};Pwd={PASSWORD};\"\n",
        "        f\"Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
        "    )\n",
        "    conn = pyodbc.connect(conn_str)\n",
        "    cursor = conn.cursor()\n",
        "    insert_sql = f\"\"\"\n",
        "    INSERT INTO {REPORT_TABLE}\n",
        "    (report_timestamp, ai_summary, avg_pm25, avg_pm10, max_co2, max_no2, high_risk_regions, generated_by, source_data_range)\n",
        "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "    \"\"\"\n",
        "    cursor.execute(\n",
        "        insert_sql,\n",
        "        datetime.now(timezone.utc),\n",
        "        ai_text_summary,\n",
        "        stats_dict.get('avg_pm25'),\n",
        "        stats_dict.get('avg_pm10'),\n",
        "        stats_dict.get('max_co2'),\n",
        "        stats_dict.get('max_no2'),\n",
        "        json.dumps(high_regions, ensure_ascii=False),\n",
        "        GENERATED_BY,\n",
        "        f\"last {int(hours_back)} hours\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    print(\"✅ Report inserted into\", REPORT_TABLE)\n",
        "\n",
        "def show_printable_results(text_summary, parsed_json):\n",
        "    print(\"\\n\\n=== HUMAN SUMMARY ===\\n\")\n",
        "    print(text_summary)\n",
        "    print(\"\\n\\n=== PARSED JSON ===\\n\")\n",
        "    print(json.dumps(parsed_json, indent=2, ensure_ascii=False))\n"
      ],
      "metadata": {
        "id": "tUsalxiv0x7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Run full AI report\n",
        "def run_ai_report(hours_back=1):\n",
        "    print(f\"Starting AI report for last {hours_back} hours...\")\n",
        "    df = load_iot_data(hours_back=hours_back)\n",
        "    if df.empty:\n",
        "        print(\"❌ No data found for this period.\")\n",
        "        return\n",
        "    display(df.head())\n",
        "    payload = compute_metrics_and_prepare(df, hours_back)\n",
        "    print(\"\\nComputed statistics:\", payload['statistics'])\n",
        "    print(\"High-risk regions:\", payload['high_risk_regions'])\n",
        "    print(\"Status:\", payload['status'])\n",
        "\n",
        "    text_summary, parsed_json, raw = produce_summary_and_json(payload)\n",
        "\n",
        "    if parsed_json is None:\n",
        "        print(\"⚠️ Warning: fallback JSON used.\")\n",
        "        s = payload['statistics']\n",
        "        parsed_json = {\n",
        "            \"avg_pm25\": s.get('avg_pm25'),\n",
        "            \"avg_pm10\": s.get('avg_pm10'),\n",
        "            \"max_co2\": s.get('max_co2'),\n",
        "            \"max_no2\": s.get('max_no2'),\n",
        "            \"high_risk_regions\": payload['high_risk_regions'],\n",
        "            \"status\": payload['status']\n",
        "        }\n",
        "\n",
        "    show_printable_results(text_summary, parsed_json)\n",
        "    insert_report_into_sql(text_summary, parsed_json, parsed_json.get('high_risk_regions', []), hours_back)\n",
        "    print(\"\\nFull raw model output preview:\\n\")\n",
        "    print(raw[:1500], \"...\\n\")\n",
        "\n",
        "# Example run\n",
        "run_ai_report(hours_back=3)\n"
      ],
      "metadata": {
        "id": "sk4Da2Mo0ztQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}