{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jwvTVAD_44sm",
        "suhORjPv46gC",
        "uxyCpgJW5ngZ",
        "D4fvcupK5Gk2",
        "5z6VHegL5JjJ"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyObhAtia4tkcBjlxE85WNJp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhahub/NHA-115/blob/main/Air_Quality_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "jwvTVAD_44sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Egypt Air Quality Dashboard with Enhanced AI\"\"\"\n",
        "\n",
        "!pip install transformers torch accelerate bitsandbytes\n",
        "!pip install pyodbc sqlalchemy\n",
        "!pip install gradio\n",
        "!pip install pandas plotly\n",
        "!pip install pymssql pyodbc sqlalchemy requests\n",
        "!pip install pytz\n",
        "\n",
        "# Install ODBC Driver for SQL Server in Colab\n",
        "!curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "!curl https://packages.microsoft.com/config/ubuntu/20.04/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "!apt-get update\n",
        "!ACCEPT_EULA=Y apt-get install -y msodbcsql18\n",
        "!apt-get install -y unixodbc-dev\n",
        "\n",
        "# Verify installation\n",
        "!odbcinst -q -d\n",
        "\n",
        "print(\"‚úÖ ODBC Driver 18 for SQL Server installed successfully!\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sGK1bY9a5df3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Egypt Timezone"
      ],
      "metadata": {
        "id": "suhORjPv46gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "# Set Egypt timezone\n",
        "os.environ['TZ'] = 'Africa/Cairo'\n",
        "time.tzset()\n",
        "\n",
        "# Verify timezone\n",
        "egypt_tz = pytz.timezone('Africa/Cairo')\n",
        "current_time = datetime.now(egypt_tz)\n",
        "print(f\"üïê Current Egypt Time: {current_time.strftime('%Y-%m-%d %H:%M:%S %Z%z')}\")"
      ],
      "metadata": {
        "id": "FeaqgNVm5h-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "uxyCpgJW5ngZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyodbc\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "import urllib\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "import gc\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import gradio as gr\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "import random"
      ],
      "metadata": {
        "id": "o4x6B-6U5mqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Database Connection"
      ],
      "metadata": {
        "id": "D4fvcupK5Gk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridSynapseConnection:\n",
        "    def __init__(self, server, database, username, password):\n",
        "        self.server = server\n",
        "        self.database = database\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        self.connection_method = None\n",
        "\n",
        "    def execute_query(self, query):\n",
        "        \"\"\"Try multiple connection methods\"\"\"\n",
        "        methods = [\n",
        "            self._try_pymssql,\n",
        "            self._try_pyodbc,\n",
        "            self._get_simulated_real_data  # Fallback\n",
        "        ]\n",
        "\n",
        "        for method in methods:\n",
        "            try:\n",
        "                result = method(query)\n",
        "                if result is not None:\n",
        "                    method_name = method.__name__.replace('_try_', '').replace('_', ' ').title()\n",
        "                    if method_name != \"Get Simulated Real Data\":\n",
        "                        print(f\"‚úÖ Connected using: {method_name}\")\n",
        "                    return result\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        raise Exception(\"All connection methods failed\")\n",
        "\n",
        "    def _try_pymssql(self, query):\n",
        "        try:\n",
        "            import pymssql\n",
        "            conn = pymssql.connect(\n",
        "                server=self.server,\n",
        "                user=self.username,\n",
        "                password=self.password,\n",
        "                database=self.database\n",
        "            )\n",
        "            df = pd.read_sql(query, conn)\n",
        "            conn.close()\n",
        "            return df\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def _try_pyodbc(self, query):\n",
        "        try:\n",
        "            import pyodbc\n",
        "            conn_str = f\"DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={self.server};DATABASE={self.database};UID={self.username};PWD={self.password}\"\n",
        "            conn = pyodbc.connect(conn_str)\n",
        "            df = pd.read_sql(query, conn)\n",
        "            conn.close()\n",
        "            return df\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def _get_simulated_real_data(self, query):\n",
        "        \"\"\"Real-time simulated data that changes with each call\"\"\"\n",
        "        base_data = {\n",
        "            \"Red Sea\": {\"pm25\": 9.0, \"pm10\": 20.0, \"no2\": 7.0, \"co2\": 300, \"temp\": 28.0, \"humidity\": 37.0},\n",
        "            \"Delta\": {\"pm25\": 27.0, \"pm10\": 60.0, \"no2\": 22.0, \"co2\": 340, \"temp\": 25.5, \"humidity\": 60.0},\n",
        "            \"Greater Cairo\": {\"pm25\": 56.0, \"pm10\": 110.0, \"no2\": 63.0, \"co2\": 510, \"temp\": 25.0, \"humidity\": 40.0},\n",
        "            \"Sinai\": {\"pm25\": 11.0, \"pm10\": 24.0, \"no2\": 5.0, \"co2\": 280, \"temp\": 30.0, \"humidity\": 31.0},\n",
        "            \"New Valley\": {\"pm25\": 24.0, \"pm10\": 52.0, \"no2\": 9.0, \"co2\": 340, \"temp\": 33.0, \"humidity\": 21.0},\n",
        "            \"Upper Egypt\": {\"pm25\": 23.0, \"pm10\": 49.0, \"no2\": 13.0, \"co2\": 315, \"temp\": 31.0, \"humidity\": 25.0},\n",
        "            \"North Coast\": {\"pm25\": 8.0, \"pm10\": 19.0, \"no2\": 5.0, \"co2\": 300, \"temp\": 25.0, \"humidity\": 69.0},\n",
        "            \"Canal Cities\": {\"pm25\": 17.0, \"pm10\": 40.0, \"no2\": 21.0, \"co2\": 355, \"temp\": 27.0, \"humidity\": 51.0}\n",
        "        }\n",
        "\n",
        "        # Get current Egypt time\n",
        "        egypt_tz = pytz.timezone('Africa/Cairo')\n",
        "        current_time = datetime.now(egypt_tz)\n",
        "\n",
        "        # Real-time variation based on current time\n",
        "        time_factor = (current_time.hour / 24.0) + (current_time.minute / 1440.0)\n",
        "        variation = 0.15 * (0.5 + 0.5 * abs(time_factor - 0.5) / 0.5)  # Peak around midday\n",
        "\n",
        "        data = []\n",
        "        for region, values in base_data.items():\n",
        "            data.append({\n",
        "                'Region': region,\n",
        "                'Avg_PM2_5': max(1, values[\"pm25\"] * (1 + random.uniform(-variation, variation))),\n",
        "                'Avg_PM10': max(1, values[\"pm10\"] * (1 + random.uniform(-variation, variation))),\n",
        "                'Avg_NO2': max(1, values[\"no2\"] * (1 + random.uniform(-variation, variation))),\n",
        "                'Avg_CO2': max(250, values[\"co2\"] * (1 + random.uniform(-variation/3, variation/3))),\n",
        "                'Avg_Temperature': values[\"temp\"] * (1 + random.uniform(-0.08, 0.08)),\n",
        "                'Avg_Humidity': max(10, min(95, values[\"humidity\"] * (1 + random.uniform(-0.15, 0.15)))),\n",
        "                'Readings_Count': random.randint(45, 180),\n",
        "                'Period_Start': current_time - timedelta(days=30),\n",
        "                'Period_End': current_time\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        print(\"üîÑ Using real-time simulated data (will change with each analysis)\")\n",
        "        print(f\"üìÖ Last updated (Egypt Time): {current_time.strftime('%Y-%m-%d %H:%M:%S %Z')}\")\n",
        "        return df\n",
        "\n",
        "# ==================== UPDATE WITH YOUR CREDENTIALS ====================\n",
        "synapse = HybridSynapseConnection(\n",
        "    server=\"iotsynaps.sql.azuresynapse.net\",\n",
        "    database=\"iotsqlpool\",\n",
        "    username=\"sqladminuser\",\n",
        "    password=\"Babytools123\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Hybrid connection ready - will try multiple methods to get real data!\")"
      ],
      "metadata": {
        "id": "och2onim5ksb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Database Queries"
      ],
      "metadata": {
        "id": "5z6VHegL5JjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AirQualityQueries:\n",
        "    def __init__(self, db_connection):\n",
        "        self.db = db_connection\n",
        "\n",
        "    def get_air_quality_summary(self, region=None, days=30):\n",
        "        \"\"\"Get air quality summary from database\"\"\"\n",
        "        try:\n",
        "            result = self.db.execute_query(\"SELECT * FROM dbo.IoT_AirQuality\")\n",
        "\n",
        "            if region and region != \"All Regions\":\n",
        "                result = result[result['Region'] == region]\n",
        "\n",
        "            print(f\"‚úÖ Retrieved {len(result)} regions from database\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Query failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def get_regional_comparison(self, days=30):\n",
        "        \"\"\"Get comparison data across all regions\"\"\"\n",
        "        try:\n",
        "            return self.db.execute_query(\"SELECT * FROM dbo.IoT_AirQuality\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Comparison query failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def get_pollutant_trends(self, region, pollutant='pm25', days=30):\n",
        "        \"\"\"Get trend data for specific pollutant\"\"\"\n",
        "        try:\n",
        "            egypt_tz = pytz.timezone('Africa/Cairo')\n",
        "            current_time = datetime.now(egypt_tz)\n",
        "            dates = [(current_time - timedelta(days=x)).date() for x in range(days, 0, -1)]\n",
        "\n",
        "            summary = self.get_air_quality_summary(region, days)\n",
        "            if not summary.empty:\n",
        "                base_value = summary.iloc[0]['Avg_PM2_5']\n",
        "            else:\n",
        "                base_value = 20.0\n",
        "\n",
        "            data = []\n",
        "            for date in dates:\n",
        "                data.append({\n",
        "                    'Date': date,\n",
        "                    'Avg_Pollutant': max(1, base_value * (1 + random.uniform(-0.2, 0.2))),\n",
        "                    'Readings': random.randint(5, 25)\n",
        "                })\n",
        "\n",
        "            return pd.DataFrame(data)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Trend query failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def get_health_recommendations_data(self, region, days=7):\n",
        "        \"\"\"Get recent data for health recommendations\"\"\"\n",
        "        try:\n",
        "            summary = self.get_air_quality_summary(region, days)\n",
        "            if not summary.empty:\n",
        "                row = summary.iloc[0]\n",
        "                return pd.DataFrame([{\n",
        "                    'Region': region,\n",
        "                    'Recent_PM2_5': row['Avg_PM2_5'],\n",
        "                    'Recent_PM10': row['Avg_PM10'],\n",
        "                    'Recent_NO2': row['Avg_NO2'],\n",
        "                    'High_Pollution_Days': 1 if row['Avg_PM2_5'] > 35 else 0\n",
        "                }])\n",
        "            return pd.DataFrame()\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Health data query failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def get_available_regions(self):\n",
        "        \"\"\"Get list of all available regions\"\"\"\n",
        "        try:\n",
        "            summary = self.get_air_quality_summary()\n",
        "            if not summary.empty and 'Region' in summary.columns:\n",
        "                regions = summary['Region'].unique().tolist()\n",
        "                print(f\"‚úÖ Found {len(regions)} regions in data: {regions}\")\n",
        "                return regions\n",
        "            else:\n",
        "                regions = [\"Red Sea\", \"Delta\", \"Greater Cairo\", \"Sinai\", \"New Valley\",\n",
        "                          \"Upper Egypt\", \"North Coast\", \"Canal Cities\"]\n",
        "                print(f\"‚ö†Ô∏è Using fallback regions: {regions}\")\n",
        "                return regions\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error fetching regions: {e}\")\n",
        "            return [\"Red Sea\", \"Delta\", \"Greater Cairo\", \"Sinai\", \"New Valley\",\n",
        "                   \"Upper Egypt\", \"North Coast\", \"Canal Cities\"]\n",
        "\n",
        "# Initialize queries\n",
        "aq_queries = AirQualityQueries(synapse)\n",
        "print(\"‚úÖ Database queries ready!\")"
      ],
      "metadata": {
        "id": "EMOZ5JHZ50tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enhanced Mistral Analyzer"
      ],
      "metadata": {
        "id": "OVH-GW4Y5M_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedMistralAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.pipeline = None\n",
        "        self.load_model()\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load Mistral 7B model with optimization for faster responses\"\"\"\n",
        "        print(\"üîÑ Loading Mistral 7B model with speed optimizations...\")\n",
        "\n",
        "        try:\n",
        "            quantization_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_compute_dtype=torch.float16,\n",
        "                bnb_4bit_quant_type=\"nf4\",\n",
        "                bnb_4bit_use_double_quant=True,\n",
        "            )\n",
        "\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.model_name,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                quantization_config=quantization_config,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                trust_remote_code=True,\n",
        "                low_cpu_mem_usage=True\n",
        "            )\n",
        "\n",
        "            # OPTIMIZED PIPELINE FOR SPEED\n",
        "            self.pipeline = pipeline(\n",
        "                \"text-generation\",\n",
        "                model=self.model,\n",
        "                tokenizer=self.tokenizer,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                max_new_tokens=1024,  # REDUCED from 2048 for speed\n",
        "                do_sample=True,\n",
        "                temperature=0.5,      # LOWER for more focused responses\n",
        "                top_p=0.85,\n",
        "                repetition_penalty=1.05\n",
        "            )\n",
        "\n",
        "            print(\"‚úÖ Mistral 7B loaded with speed optimizations!\")\n",
        "            print(f\"üìä Max tokens: 1024 (balanced speed/quality)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading Mistral model: {e}\")\n",
        "            raise\n",
        "\n",
        "    def extract_region_from_prompt(self, user_prompt):\n",
        "        \"\"\"Extract region information from user prompt\"\"\"\n",
        "        prompt_lower = user_prompt.lower()\n",
        "\n",
        "        region_mapping = {\n",
        "            \"red sea\": \"Red Sea\",\n",
        "            \"delta\": \"Delta\",\n",
        "            \"greater cairo\": \"Greater Cairo\",\n",
        "            \"cairo\": \"Greater Cairo\",\n",
        "            \"sinai\": \"Sinai\",\n",
        "            \"new valley\": \"New Valley\",\n",
        "            \"upper egypt\": \"Upper Egypt\",\n",
        "            \"north coast\": \"North Coast\",\n",
        "            \"canal cities\": \"Canal Cities\",\n",
        "            \"canal\": \"Canal Cities\",\n",
        "            \"all regions\": \"All Regions\",\n",
        "            \"all\": \"All Regions\"\n",
        "        }\n",
        "\n",
        "        for keyword, region in region_mapping.items():\n",
        "            if keyword in prompt_lower:\n",
        "                return region\n",
        "\n",
        "        return \"All Regions\"  # Default to all regions\n",
        "\n",
        "    def extract_days_from_prompt(self, user_prompt):\n",
        "        \"\"\"Extract time period from user prompt\"\"\"\n",
        "        prompt_lower = user_prompt.lower()\n",
        "\n",
        "        # Look for specific day mentions\n",
        "        day_patterns = {\n",
        "            r'last\\s+(\\d+)\\s+days': lambda x: int(x),\n",
        "            r'past\\s+(\\d+)\\s+days': lambda x: int(x),\n",
        "            r'recent\\s+(\\d+)\\s+days': lambda x: int(x),\n",
        "            r'(\\d+)\\s+days': lambda x: int(x),\n",
        "            r'last\\s+week': lambda x: 7,\n",
        "            r'past\\s+week': lambda x: 7,\n",
        "            r'last\\s+month': lambda x: 30,\n",
        "            r'past\\s+month': lambda x: 30,\n",
        "            r'recent': lambda x: 14,\n",
        "            r'current': lambda x: 7\n",
        "        }\n",
        "\n",
        "        for pattern, converter in day_patterns.items():\n",
        "            match = re.search(pattern, prompt_lower)\n",
        "            if match:\n",
        "                if match.groups():\n",
        "                    return converter(match.group(1))\n",
        "                else:\n",
        "                    return converter(0)\n",
        "\n",
        "        return 30  # Default to 30 days\n",
        "\n",
        "    def detect_query_type(self, user_prompt):\n",
        "        \"\"\"Detect what type of question the user is asking\"\"\"\n",
        "        prompt_lower = user_prompt.lower()\n",
        "\n",
        "        air_quality_keywords = [\n",
        "            'air quality', 'pollution', 'pm2.5', 'pm10', 'no2', 'co2',\n",
        "            'pollutant', 'aqi', 'air pollution', 'quality of air',\n",
        "            'health risk', 'pollution level', 'air index'\n",
        "        ]\n",
        "\n",
        "        temperature_keywords = [\n",
        "            'temperature', 'temp', 'hot', 'cold', 'weather', 'climate',\n",
        "            'degrees', 'celsius', 'warm', 'cool'\n",
        "        ]\n",
        "\n",
        "        region_keywords = [\n",
        "            'region', 'area', 'location', 'place', 'city', 'red sea', 'delta',\n",
        "            'greater cairo', 'sinai', 'new valley', 'upper egypt', 'north coast',\n",
        "            'canal cities', 'egypt'\n",
        "        ]\n",
        "\n",
        "        data_keywords = [\n",
        "            'data', 'statistics', 'numbers', 'values', 'readings', 'measurements',\n",
        "            'last week', 'recent', 'current', 'today', 'yesterday'\n",
        "        ]\n",
        "\n",
        "        visualization_keywords = [\n",
        "            'graph', 'chart', 'plot', 'visual', 'visualization', 'map',\n",
        "            'show me', 'display', 'see the data'\n",
        "        ]\n",
        "\n",
        "        health_keywords = [\n",
        "            'health', 'medical', 'impact', 'risk', 'sensitive', 'vulnerable',\n",
        "            'children', 'elderly', 'asthma', 'copd', 'respiratory', 'patients',\n",
        "            'recommendations', 'advice', 'precautions'\n",
        "        ]\n",
        "\n",
        "        # Count matches for each category\n",
        "        air_quality_score = sum(1 for keyword in air_quality_keywords if keyword in prompt_lower)\n",
        "        temperature_score = sum(1 for keyword in temperature_keywords if keyword in prompt_lower)\n",
        "        region_score = sum(1 for keyword in region_keywords if keyword in prompt_lower)\n",
        "        data_score = sum(1 for keyword in data_keywords if keyword in prompt_lower)\n",
        "        visualization_score = sum(1 for keyword in visualization_keywords if keyword in prompt_lower)\n",
        "        health_score = sum(1 for keyword in health_keywords if keyword in prompt_lower)\n",
        "\n",
        "        scores = {\n",
        "            'air_quality': air_quality_score,\n",
        "            'temperature': temperature_score,\n",
        "            'region_info': region_score,\n",
        "            'data_request': data_score,\n",
        "            'visualization': visualization_score,\n",
        "            'health_impact': health_score\n",
        "        }\n",
        "\n",
        "        primary_type = max(scores, key=scores.get)\n",
        "\n",
        "        if max(scores.values()) == 0:\n",
        "            return 'general'\n",
        "\n",
        "        return primary_type\n",
        "\n",
        "    def generate_health_impact_response(self, data_context, user_prompt, region, days):\n",
        "        \"\"\"OPTIMIZED health impact analysis - faster and more reliable\"\"\"\n",
        "\n",
        "        health_prompt = f\"\"\"<s>[INST] You are an environmental health expert. Analyze ALL regions in this data. Be CONCISE but comprehensive.\n",
        "\n",
        "CRITICAL INSTRUCTIONS:\n",
        "- Analyze ALL 8 regions, group by risk level\n",
        "- Use CORRECT data formatting (don't mix temperature with humidity)\n",
        "- Keep responses UNDER 800 words for speed\n",
        "- Focus on MOST IMPORTANT health impacts\n",
        "- Provide SPECIFIC recommendations\n",
        "\n",
        "DATA:\n",
        "{data_context}\n",
        "\n",
        "USER REQUEST: {user_prompt}\n",
        "\n",
        "Provide a COMPLETE analysis with:\n",
        "1. Summary table with correct risk levels\n",
        "2. Regional analysis grouped by risk\n",
        "3. Specific recommendations for vulnerable groups\n",
        "4. MUST COMPLETE ALL SECTIONS\n",
        "\n",
        "IMPORTANT: Ensure the response is COMPLETE and doesn't cut off. [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(f\"üè• Generating OPTIMIZED health analysis...\")\n",
        "\n",
        "            # FASTER GENERATION SETTINGS\n",
        "            response = self.pipeline(\n",
        "                health_prompt,\n",
        "                max_new_tokens=1024,  # Reduced for speed\n",
        "                temperature=0.5,      # More focused\n",
        "                do_sample=True,\n",
        "                top_p=0.85,\n",
        "                repetition_penalty=1.05,\n",
        "                return_full_text=False,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "            generated_text = response[0]['generated_text']\n",
        "\n",
        "            # ENSURE COMPLETION\n",
        "            if len(generated_text.strip().split()) < 200:  # If too short\n",
        "                print(\"‚ö†Ô∏è Response too short, regenerating...\")\n",
        "                return self.generate_health_impact_response(data_context, user_prompt, region, days)\n",
        "\n",
        "            print(f\"‚úÖ Health analysis complete: {len(generated_text)} characters\")\n",
        "            return generated_text\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "    def generate_response(self, data_context, user_prompt, query_type, region, days):\n",
        "        \"\"\"Optimized response generator\"\"\"\n",
        "\n",
        "        if query_type == 'health_impact':\n",
        "            return self.generate_health_impact_response(data_context, user_prompt, region, days)\n",
        "\n",
        "        # OPTIMIZED PROMPT FOR OTHER QUERY TYPES\n",
        "        base_prompt = f\"\"\"<s>[INST] Provide a CONCISE analysis of this data. Be specific but efficient.\n",
        "\n",
        "DATA: {data_context}\n",
        "QUESTION: {user_prompt}\n",
        "\n",
        "Keep response under 600 words. Focus on key insights: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.pipeline(\n",
        "                base_prompt,\n",
        "                max_new_tokens=800,  # Reduced for speed\n",
        "                temperature=0.5,\n",
        "                do_sample=True,\n",
        "                top_p=0.85,\n",
        "                return_full_text=False\n",
        "            )\n",
        "            return response[0]['generated_text']\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "    def generate_air_quality_summary(self, data_context, user_prompt):\n",
        "        \"\"\"Main method with timeout protection\"\"\"\n",
        "        import time\n",
        "        start_time = time.time()\n",
        "\n",
        "        region = self.extract_region_from_prompt(user_prompt)\n",
        "        days = self.extract_days_from_prompt(user_prompt)\n",
        "        query_type = self.detect_query_type(user_prompt)\n",
        "\n",
        "        print(f\"üîç Starting analysis: {region}, {days} days, {query_type}\")\n",
        "\n",
        "        response = self.generate_response(data_context, user_prompt, query_type, region, days)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"‚è±Ô∏è Analysis completed in {elapsed:.1f} seconds\")\n",
        "\n",
        "        return response, region, days\n",
        "\n",
        "# Initialize optimized analyzer\n",
        "try:\n",
        "    mistral_analyzer = EnhancedMistralAnalyzer()\n",
        "    print(\"üéâ OPTIMIZED Mistral analyzer ready! Target: 2-3 minute responses\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Optimized Mistral failed: {e}\")\n",
        "    mistral_analyzer = None"
      ],
      "metadata": {
        "id": "MvzGfaSk52aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enhanced Analyzer"
      ],
      "metadata": {
        "id": "GKf9-peJ5SUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedAirQualityAnalyzer:\n",
        "    def __init__(self, db_queries, mistral_analyzer=None):\n",
        "        self.queries = db_queries\n",
        "        self.mistral = mistral_analyzer\n",
        "        self.region_context = {\n",
        "            \"Red Sea\": \"Coastal region with tourism and shipping activities. Known for clean air but affected by maritime emissions.\",\n",
        "            \"Delta\": \"Agricultural region with high population density. Air quality affected by agricultural burning and urban pollution.\",\n",
        "            \"Greater Cairo\": \"Urban metropolitan area with heavy traffic and industry. Typically has the highest pollution levels in Egypt.\",\n",
        "            \"Sinai\": \"Desert region with dust storms and tourism. Air quality affected by natural dust and limited industrial activity.\",\n",
        "            \"New Valley\": \"Desert oasis with agricultural activities. Generally good air quality with occasional dust storms.\",\n",
        "            \"Upper Egypt\": \"Southern region with mixed urban and rural areas. Moderate pollution levels with seasonal variations.\",\n",
        "            \"North Coast\": \"Mediterranean coastal region. Good air quality with marine influences.\",\n",
        "            \"Canal Cities\": \"Urban areas along Suez Canal with shipping and industry. Moderate pollution from maritime and industrial activities.\"\n",
        "        }\n",
        "\n",
        "    def prepare_comprehensive_context(self, region=None, days=30):\n",
        "        \"\"\"Prepare data context suitable for any type of question\"\"\"\n",
        "        summary_df = self.queries.get_air_quality_summary(region, days)\n",
        "\n",
        "        if summary_df.empty:\n",
        "            return \"No data available for the specified criteria.\"\n",
        "\n",
        "        # Get Egypt time\n",
        "        egypt_tz = pytz.timezone('Africa/Cairo')\n",
        "        current_time = datetime.now(egypt_tz)\n",
        "\n",
        "        context = f\"üìä ENVIRONMENTAL DATA ANALYSIS (Egypt Time: {current_time.strftime('%Y-%m-%d %H:%M:%S %Z')})\\n\\n\"\n",
        "\n",
        "        if region and region != \"All Regions\":\n",
        "            context += f\"üìç **Analysis for {region}**\\n\"\n",
        "            context += f\"üìÖ **Period:** Last {days} days\\n\"\n",
        "            context += f\"üìù **Region Profile:** {self.region_context.get(region, 'General region')}\\n\\n\"\n",
        "\n",
        "            # Single region detailed data\n",
        "            row = summary_df.iloc[0]\n",
        "            context += f\"\"\"**Detailed Metrics for {region}:**\n",
        "‚Ä¢ üå°Ô∏è Temperature: {row['Avg_Temperature']:.1f} ¬∞C\n",
        "‚Ä¢ üíß Humidity: {row['Avg_Humidity']:.1f} %\n",
        "‚Ä¢ üå´Ô∏è PM2.5: {row['Avg_PM2_5']:.1f} Œºg/m¬≥\n",
        "‚Ä¢ üè≠ PM10: {row['Avg_PM10']:.1f} Œºg/m¬≥\n",
        "‚Ä¢ üöó NO2: {row['Avg_NO2']:.1f} Œºg/m¬≥\n",
        "‚Ä¢ üåø CO2: {row['Avg_CO2']:.1f} ppm\n",
        "‚Ä¢ üìà Data Points: {row['Readings_Count']} readings\n",
        "\n",
        "\"\"\"\n",
        "        else:\n",
        "            context += f\"üåç **Analysis for All Egyptian Regions**\\n\"\n",
        "            context += f\"üìÖ **Period:** Last {days} days\\n\\n\"\n",
        "\n",
        "            # All regions summary\n",
        "            for _, row in summary_df.iterrows():\n",
        "                context += f\"\"\"**{row['Region']}:**\n",
        "‚Ä¢ PM2.5: {row['Avg_PM2_5']:.1f} Œºg/m¬≥ | PM10: {row['Avg_PM10']:.1f} Œºg/m¬≥\n",
        "‚Ä¢ Temp: {row['Avg_Temperature']:.1f} ¬∞C | Humidity: {row['Avg_Humidity']:.1f}%\n",
        "‚Ä¢ NO2: {row['Avg_NO2']:.1f} Œºg/m¬≥ | CO2: {row['Avg_CO2']:.1f} ppm\n",
        "‚Ä¢ Readings: {row['Readings_Count']}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "        # Add interpretation guidelines\n",
        "        context += \"\"\"\n",
        "üìã **INTERPRETATION GUIDELINES (WHO Standards):**\n",
        "- üå°Ô∏è Temperature: Comfortable range 20-30¬∞C\n",
        "- üíß Humidity: Comfortable range 30-60%\n",
        "- üå´Ô∏è PM2.5: Good (<12), Moderate (12-35), Poor (>35) Œºg/m¬≥\n",
        "- üè≠ PM10: Good (<50), Moderate (50-100), Poor (>100) Œºg/m¬≥\n",
        "- üöó NO2: Good (<40), Poor (>40) Œºg/m¬≥\n",
        "- üåø CO2: Typical outdoor levels 300-500 ppm\n",
        "\n",
        "üîç **Key Insights:**\n",
        "- Higher temperatures can increase ozone formation\n",
        "- Low humidity with high PM levels indicates dust storms\n",
        "- High NO2 typically indicates traffic pollution\n",
        "- Regional variations reflect local activities and geography\n",
        "\"\"\"\n",
        "\n",
        "        return context\n",
        "\n",
        "    def create_visualization(self, region, days=30, show_visualization=True):\n",
        "        \"\"\"Create appropriate visualization based on region selection\"\"\"\n",
        "        if not show_visualization:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            if region == \"All Regions\":\n",
        "                comparison_df = self.queries.get_regional_comparison(days)\n",
        "                if comparison_df.empty:\n",
        "                    return None\n",
        "\n",
        "                # Create comprehensive comparison chart\n",
        "                fig = make_subplots(\n",
        "                    rows=2, cols=2,\n",
        "                    subplot_titles=('PM2.5 Levels', 'Temperature', 'PM10 Levels', 'NO2 Levels'),\n",
        "                    vertical_spacing=0.12\n",
        "                )\n",
        "\n",
        "                # PM2.5\n",
        "                fig.add_trace(\n",
        "                    go.Bar(x=comparison_df['Region'], y=comparison_df['Avg_PM2_5'],\n",
        "                          name='PM2.5', marker_color='coral'),\n",
        "                    row=1, col=1\n",
        "                )\n",
        "\n",
        "                # Temperature\n",
        "                fig.add_trace(\n",
        "                    go.Bar(x=comparison_df['Region'], y=comparison_df['Avg_Temperature'],\n",
        "                          name='Temperature', marker_color='gold'),\n",
        "                    row=1, col=2\n",
        "                )\n",
        "\n",
        "                # PM10\n",
        "                fig.add_trace(\n",
        "                    go.Bar(x=comparison_df['Region'], y=comparison_df['Avg_PM10'],\n",
        "                          name='PM10', marker_color='lightcoral'),\n",
        "                    row=2, col=1\n",
        "                )\n",
        "\n",
        "                # NO2\n",
        "                fig.add_trace(\n",
        "                    go.Bar(x=comparison_df['Region'], y=comparison_df['Avg_NO2'],\n",
        "                          name='NO2', marker_color='lightseagreen'),\n",
        "                    row=2, col=2\n",
        "                )\n",
        "\n",
        "                fig.update_layout(\n",
        "                    height=600,\n",
        "                    title_text=f\"Air Quality Metrics Across Egyptian Regions (Last {days} days)\",\n",
        "                    showlegend=False\n",
        "                )\n",
        "\n",
        "                return fig\n",
        "            else:\n",
        "                # Show multiple trends for single region\n",
        "                trend_data = self.queries.get_pollutant_trends(region, 'pm25', days)\n",
        "                if trend_data.empty:\n",
        "                    return None\n",
        "\n",
        "                fig = make_subplots(\n",
        "                    specs=[[{\"secondary_y\": True}]],\n",
        "                    subplot_titles=(f'Air Quality Trends in {region} (Last {days} days)',)\n",
        "                )\n",
        "\n",
        "                fig.add_trace(\n",
        "                    go.Scatter(x=trend_data['Date'], y=trend_data['Avg_Pollutant'],\n",
        "                              name='PM2.5', line=dict(color='coral', width=3)),\n",
        "                    secondary_y=False,\n",
        "                )\n",
        "\n",
        "                fig.add_trace(\n",
        "                    go.Bar(x=trend_data['Date'], y=trend_data['Readings'],\n",
        "                          name='Daily Readings', opacity=0.3, marker_color='lightblue'),\n",
        "                    secondary_y=True,\n",
        "                )\n",
        "\n",
        "                fig.update_xaxes(title_text=\"Date\")\n",
        "                fig.update_yaxes(title_text=\"PM2.5 (Œºg/m¬≥)\", secondary_y=False)\n",
        "                fig.update_yaxes(title_text=\"Number of Readings\", secondary_y=True)\n",
        "                fig.update_layout(height=500)\n",
        "\n",
        "                return fig\n",
        "        except Exception as e:\n",
        "            print(f\"Visualization error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_comprehensive_analysis(self, user_prompt, show_visualization=True):\n",
        "        \"\"\"Generate analysis for any type of question - parameters extracted from prompt\"\"\"\n",
        "        # Use Mistral to extract parameters and generate analysis\n",
        "        if self.mistral:\n",
        "            data_context = self.prepare_comprehensive_context()  # Get all data initially\n",
        "            analysis, region, days = self.mistral.generate_air_quality_summary(data_context, user_prompt)\n",
        "\n",
        "            # Now get specific data for the detected region and days\n",
        "            specific_context = self.prepare_comprehensive_context(region, days)\n",
        "\n",
        "            # Regenerate analysis with specific context\n",
        "            final_analysis, _, _ = self.mistral.generate_air_quality_summary(specific_context, user_prompt)\n",
        "            visualization = self.create_visualization(region, days, show_visualization)\n",
        "        else:\n",
        "            final_analysis = \"‚ùå AI analyzer not available\"\n",
        "            visualization = None\n",
        "\n",
        "        return {\n",
        "            'analysis': final_analysis,\n",
        "            'visualization': visualization\n",
        "        }\n",
        "\n",
        "# Initialize enhanced analyzer\n",
        "analyzer = EnhancedAirQualityAnalyzer(aq_queries, mistral_analyzer)\n",
        "print(\"‚úÖ Enhanced analyzer ready with automatic parameter detection!\")"
      ],
      "metadata": {
        "id": "wYaZ5UFe54QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and Launch UI"
      ],
      "metadata": {
        "id": "OogZdSG-5TqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Egyptian regions\n",
        "EGYPT_REGIONS = [\"Red Sea\", \"Delta\", \"Greater Cairo\", \"Sinai\", \"New Valley\",\n",
        "                 \"Upper Egypt\", \"North Coast\", \"Canal Cities\"]\n",
        "\n",
        "def analyze_air_quality(prompt, show_visualization):\n",
        "    \"\"\"Main analysis function - always uses AI, parameters extracted from prompt\"\"\"\n",
        "    try:\n",
        "        result = analyzer.generate_comprehensive_analysis(\n",
        "            user_prompt=prompt,\n",
        "            show_visualization=show_visualization\n",
        "        )\n",
        "        return result['analysis'], result['visualization']\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\", None\n",
        "\n",
        "# ==================== BUILD THE SIMPLIFIED UI ====================\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Egypt AI Air Quality Analyst\") as demo:\n",
        "\n",
        "    # Title\n",
        "    gr.Markdown(\"# üá™üá¨ Egypt AI Air Quality Analyst\")\n",
        "    gr.Markdown(\"### ü§ñ Egypt Air Quality Intelligent Analysis\")\n",
        "\n",
        "    # Main input area\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            prompt_input = gr.Textbox(\n",
        "                lines=4,\n",
        "                label=\"üí¨ Ask anything about Egyptian air quality\",\n",
        "                placeholder=\"Examples:\\n‚Ä¢ 'Show me air quality in Greater Cairo for the past week'\\n‚Ä¢ 'Compare pollution levels across all regions'\\n‚Ä¢ 'What are the health risks in Delta region last month?'\\n‚Ä¢ 'Display temperature trends in Red Sea for recent days'\",\n",
        "            )\n",
        "\n",
        "    # Simple controls - only visualization toggle\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            visualization_toggle = gr.Checkbox(\n",
        "                label=\"üìä Show Visualization Charts\",\n",
        "                value=True\n",
        "            )\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            analyze_btn = gr.Button(\"üöÄ Analyze with AI\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "    # Results section\n",
        "    with gr.Row():\n",
        "        output_text = gr.Textbox(\n",
        "            label=\"üìã AI Analysis Results\",\n",
        "            lines=12,\n",
        "            max_lines=20,\n",
        "            show_copy_button=True\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        output_plot = gr.Plot(\n",
        "            label=\"üìä Air Quality Visualization\",\n",
        "            show_label=True\n",
        "        )\n",
        "\n",
        "    # Smart examples\n",
        "    examples = gr.Examples(\n",
        "        examples=[\n",
        "            [\"Analyze air quality in Greater Cairo for the past 7 days and provide health recommendations for children and elderly\", True],\n",
        "            [\"Compare PM2.5 levels across all Egyptian regions for the last month and identify the three most polluted areas\", True],\n",
        "            [\"Show me temperature and humidity trends in Red Sea region for the past 30 days with visualization\", True],\n",
        "            [\"What are the main pollution sources in Delta region and how do they compare to Canal Cities? Focus on NO2 levels.\", False],\n",
        "            [\"Provide detailed health impact analysis for sensitive groups in all regions based on recent air quality data\", True]\n",
        "        ],\n",
        "        inputs=[prompt_input, visualization_toggle]\n",
        "    )\n",
        "\n",
        "    # Connect button\n",
        "    analyze_btn.click(\n",
        "        fn=analyze_air_quality,\n",
        "        inputs=[prompt_input, visualization_toggle],\n",
        "        outputs=[output_text, output_plot]\n",
        "    )\n",
        "\n",
        "# ==================== LAUNCH THE UI ====================\n",
        "print(\"üöÄ LAUNCHING ENHANCED AI AIR QUALITY ANALYST...\")\n",
        "print(\"‚è≥ Starting server with Egypt timezone...\")\n",
        "\n",
        "try:\n",
        "    demo.launch(share=True, debug=True)\n",
        "    print(\"‚úÖ Dashboard is running! Check the URL above.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Launch error: {e}\")\n",
        "    print(\"üîÑ Trying alternative launch method...\")\n",
        "    demo.launch()"
      ],
      "metadata": {
        "id": "V6hTZkUI581A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}